{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da39a1b0-b8d3-425d-b5eb-63cdc79dfc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Requirement already satisfied: opencv_python in c:\\users\\rohan\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from opencv_python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c8fabf-dfb3-4f99-b0d1-15b9db2f14e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in c:\\users\\rohan\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from mtcnn) (3.5.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from mtcnn) (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from keras>=2.0.0->mtcnn) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from optree->keras>=2.0.0->mtcnn) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from rich->keras>=2.0.0->mtcnn) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from rich->keras>=2.0.0->mtcnn) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rohan\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# converting from pdf format to jpg format\n",
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75245a9b-7e52-4405-b915-ae37b71ef001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extracted_image_page_1_img_1.jpeg\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    for page_num in range(len(pdf_document)):\n",
    "        page = pdf_document[page_num]\n",
    "        image_list = page.get_images(full=True)  # Get the images on the page\n",
    "        \n",
    "        for img_index, img in enumerate(image_list):\n",
    "            xref = img[0]  # The xref number of the image\n",
    "            base_image = pdf_document.extract_image(xref)  # Extract the image\n",
    "            image_bytes = base_image[\"image\"]  # Get the image bytes\n",
    "            image_extension = base_image[\"ext\"]  # Get the image extension\n",
    "            \n",
    "            # Save the image\n",
    "            image_filename = f\"extracted_image_page_{page_num+1}_img_{img_index+1}.{image_extension}\"\n",
    "            with open(image_filename, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "                print(f\"Saved {image_filename}\")\n",
    "    \n",
    "    pdf_document.close()\n",
    "\n",
    "# Usage\n",
    "extract_images_from_pdf(\"Pan.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5af99a-29ca-40a7-8ed5-9527a501b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def preprocess_document(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance contrast using CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray = clahe.apply(gray)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Darken the grayscale image\n",
    "    dark_gray = cv2.addWeighted(gray, 0.5, np.zeros(gray.shape, gray.dtype), 0, 0)  # Reduces brightness\n",
    "\n",
    "    # Unsharp Masking\n",
    "    # Create a Gaussian kernel\n",
    "    gaussian_blur = cv2.GaussianBlur(dark_gray, (5, 5), 0)\n",
    "    # Subtract the Gaussian blur from the original image to enhance edges\n",
    "    unsharp_masked = cv2.addWeighted(dark_gray, 2.5, gaussian_blur, -0.5, 0)  # 1.5 is the weight for sharpening\n",
    "\n",
    "    # Use Canny edge detection\n",
    "    edges = cv2.Canny(unsharp_masked, 50, 150)\n",
    "\n",
    "    # Optional: Resize image to standard size\n",
    "    processed_image = cv2.resize(unsharp_masked, (600, 400))\n",
    "\n",
    "    return processed_image\n",
    "\n",
    "def augment_image(image):\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-15, 15)  # Rotate between -15 and 15 degrees\n",
    "    height, width = image.shape[:2]\n",
    "    center = (width // 2, height // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, M, (width, height))\n",
    "\n",
    "    # Random scaling\n",
    "    scale = random.uniform(0.9, 1.1)  # Scale between 90% and 110%\n",
    "    scaled_image = cv2.resize(rotated_image, None, fx=scale, fy=scale)\n",
    "\n",
    "    return scaled_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b8561a-a0e7-412a-b29c-291e40cd9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved to processed_pusu_image.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main(image_path, output_path):\n",
    "    # Preprocess the document\n",
    "    processed_image = preprocess_document(image_path)\n",
    "\n",
    "    # Augment the image\n",
    "    #augmented_image = augment_image(processed_image)#\n",
    "\n",
    "    # Save the final image\n",
    "    cv2.imwrite(output_path, processed_image)\n",
    "    print(f\"Processed image saved to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "image_path = \"pusu.jpg\"\n",
    "output_path = \"processed_pusu_image.jpg\"\n",
    "main(image_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26c21d-1a41-43e5-bb42-18da1bae1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "def detect_face(image):\n",
    "    \"\"\"\n",
    "    Detect faces in an image using MTCNN.\n",
    "    \"\"\"\n",
    "    detector = MTCNN()\n",
    "    faces = detector.detect_faces(image)\n",
    "    return faces\n",
    "\n",
    "def extract_face(image, face):\n",
    "    \"\"\"\n",
    "    Extract the face from the image based on the bounding box provided by MTCNN.\n",
    "    \"\"\"\n",
    "    x, y, width, height = face['box']  # Extract the bounding box\n",
    "    # Ensure the bounding box is within image dimensions\n",
    "    x = max(0, x)\n",
    "    y = max(0, y)\n",
    "    width = min(width, image.shape[1] - x)\n",
    "    height = min(height, image.shape[0] - y)\n",
    "    extracted_face = image[y:y + height, x:x + width]\n",
    "    return extracted_face\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotate the image by the specified angle.\n",
    "    \"\"\"\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, matrix, (w, h))\n",
    "    return rotated\n",
    "\n",
    "# Main workflow\n",
    "image_path = 'processed_pusu_image.jpg'  # Replace with your preprocessed image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to RGB\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Attempt to detect faces\n",
    "faces = detect_face(rgb_image)\n",
    "\n",
    "# Define the angles to try if no faces are detected\n",
    "rotation_angles = [0,90, 180, 270 ,0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180 , 195, 210, 225, 240, 255, 270, 285, 300, 315,330]\n",
    "\n",
    "# Rotate the image if no faces are detected\n",
    "for angle in rotation_angles:\n",
    "    if faces:  # Break the loop if faces are found\n",
    "        break\n",
    "    print(f\"No face detected. Rotating the image by {angle} degrees.\")\n",
    "    rgb_image = rotate_image(rgb_image, angle)\n",
    "    faces = detect_face(rgb_image)\n",
    "\n",
    "# Process the detected face\n",
    "if faces:\n",
    "    # Extract the first detected face\n",
    "    extracted_face = extract_face(rgb_image, faces[0])\n",
    "\n",
    "    # Save the extracted face\n",
    "    output_path = 'extracted_face_pusu.jpg'\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(extracted_face, cv2.COLOR_RGB2BGR))  # Save as BGR for OpenCV\n",
    "    print(f\"Face extracted and saved at {output_path}.\")\n",
    "\n",
    "    # Optionally display the extracted face\n",
    "    cv2.imshow('Extracted Face', extracted_face)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No faces detected in the image after all rotations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20a2b8a-eee6-406a-aaf9-8538d6788c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
